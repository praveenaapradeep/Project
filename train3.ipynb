{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Importing libraries"
      ],
      "metadata": {
        "id": "gKNQ8pk38U8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as plx\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import pickle"
      ],
      "metadata": {
        "id": "ofTu91fo8WeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Mount Google Drive and Load Data"
      ],
      "metadata": {
        "id": "IQ7jYSxFAWAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f1sxu6EF8zhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8XaAtH4bAhhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset from Google Drive into a pandas DataFrame\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/praveena stock/prices.csv\")"
      ],
      "metadata": {
        "id": "8ZRWA2WQ8zjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PPP4q1rOAivZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display dataset dimensions\n",
        "print(\"Dataset Shape:\", data.shape)"
      ],
      "metadata": {
        "id": "5YmzhUbo8zl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "joucyryDAjn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"First 5 rows of the dataset:\\n\", data.head())"
      ],
      "metadata": {
        "id": "rJXqVEjY8zoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d0X1BwdiAkc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique stock symbols and their counts\n",
        "unique_symbols = data['symbol'].value_counts()\n",
        "print(\"Unique Symbols Count:\\n\", unique_symbols)"
      ],
      "metadata": {
        "id": "UDHhU-Ts8zqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-lmsEZOcAlUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "data.info()"
      ],
      "metadata": {
        "id": "kFiCHXaD8ztM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Filtering and Visualizing Stock Data"
      ],
      "metadata": {
        "id": "5iRoGm43AmWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for Google stock (symbol: GOOG)\n",
        "google = data[data['symbol'] == 'GOOG']\n",
        "print(\"Google Stock Data:\\n\", google.head())\n",
        "print(\"Google Stock Data Shape:\", google.shape)"
      ],
      "metadata": {
        "id": "NnG9Rg3l8zuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Google stock data: open vs. close prices\n",
        "plx.line(google, x=\"date\", y=[\"open\", \"close\"], title=\"Difference between open and close prices of Google stocks\")"
      ],
      "metadata": {
        "id": "9ZPUDGEb8zw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Google stock data: high vs. low prices\n",
        "plx.line(google, x=\"date\", y=[\"high\", \"low\"], title=\"Difference between high and low prices of Google stocks\")\n",
        "\n"
      ],
      "metadata": {
        "id": "KF774KUh8zzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Plot Google stock data: volume traded\n",
        "plx.line(google, x=\"date\", y=[\"volume\"], title=\"Volume of stock traded\")\n",
        "\n"
      ],
      "metadata": {
        "id": "H1LaD8vc8z1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data for Facebook stock (symbol: FB)\n",
        "facebook = data[data['symbol'] == 'FB']\n",
        "\n"
      ],
      "metadata": {
        "id": "hQXog0Zp8z30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Facebook stock data: open vs. close prices\n",
        "plx.line(facebook, x=\"date\", y=[\"open\", \"close\"], title=\"Difference between open and close prices of FB stocks\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4VU3VdMI8z5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Facebook stock data: high vs. low prices\n",
        "plx.line(facebook, x=\"date\", y=[\"high\", \"low\"], title=\"Difference between high and low prices of Facebook stocks\")\n",
        "\n"
      ],
      "metadata": {
        "id": "baDl6Pkr8z8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Facebook stock data: volume traded\n",
        "plx.line(facebook, x=\"date\", y=[\"volume\"], title=\"Volume of stock traded\")\n",
        "\n"
      ],
      "metadata": {
        "id": "bg5Px5BL8z-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Handling Imbalanced Data with SMOTE"
      ],
      "metadata": {
        "id": "KKgE_0X0EPgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply SMOTE to handle class imbalance in Facebook data\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_fb_resampled, y_fb_resampled = smote.fit_resample(X_fb, y_fb)\n",
        "\n"
      ],
      "metadata": {
        "id": "1Gvo7kvY80Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from resampled data\n",
        "upsampled_fb = pd.DataFrame(X_fb_resampled, columns=X_fb.columns)\n",
        "upsampled_fb['symbol'] = y_fb_resampled\n",
        "upsampled_fb.reset_index(drop=True, inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "mTFNLHzF80DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add random dates to the upsampled data\n",
        "upsampled_fb['date'] = np.random.choice(facebook['date'], size=len(upsampled_fb), replace=True)"
      ],
      "metadata": {
        "id": "V3GQLWIM80E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display unique symbols and shape of upsampled data\n",
        "print(\"Upsampled Symbols Count:\\n\", upsampled_fb['symbol'].value_counts())\n",
        "print(\"Upsampled Data Shape:\", upsampled_fb.shape)"
      ],
      "metadata": {
        "id": "7H5uc6xv80Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Preparing Data for Google Stock Prediction"
      ],
      "metadata": {
        "id": "At2qdQ5ZExp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and sort Google data from upsampled data\n",
        "google = upsampled_fb[upsampled_fb[\"symbol\"] == 'GOOG']\n",
        "google = google.sort_values(by='date')\n",
        "google.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "wSXZX0-wEoqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize closing prices using MinMaxScaler\n",
        "close_prices = google['close'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "close_prices_normalized = scaler.fit_transform(close_prices)"
      ],
      "metadata": {
        "id": "JQXRamHzE0DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Creating Datasets for Training and Testing"
      ],
      "metadata": {
        "id": "HdYmkQDNFEey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(data, win_size):\n",
        "    \"\"\"\n",
        "    Create datasets for training a time series model.\n",
        "\n",
        "    Parameters:\n",
        "    - data (numpy.ndarray): Normalized close prices.\n",
        "    - win_size (int): Size of the time window.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: (X, Y) where X is the input features and Y is the target values.\n",
        "    \"\"\"\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - win_size - 1):\n",
        "        X.append(data[i:(i + win_size), 0])\n",
        "        Y.append(data[i + win_size, 0])\n",
        "    return np.array(X), np.array(Y)"
      ],
      "metadata": {
        "id": "_cYQsO9JE0QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define window size for time series\n",
        "win_size = 20"
      ],
      "metadata": {
        "id": "GRm1wnEBE0UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing datasets\n",
        "X, Y = create_dataset(close_prices_normalized, win_size)\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "train_size = int(len(X) * 0.8)\n",
        "train_X, test_X = X[0:train_size], X[train_size:]\n",
        "train_Y, test_Y = Y[0:train_size], Y[train_size:]"
      ],
      "metadata": {
        "id": "-aPScROcE0Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save test data\n",
        "with open('google.pkl', 'wb') as file:\n",
        "    pickle.dump(test_X, file)"
      ],
      "metadata": {
        "id": "oFNqDJ0zE0bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Building and Training the Model"
      ],
      "metadata": {
        "id": "ns5gtjYnFdfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and compile the GRU model\n",
        "model = Sequential()\n",
        "model.add(GRU(units=50, return_sequences=True, input_shape=(1, win_size)))\n",
        "model.add(GRU(units=50, return_sequences=True))\n",
        "model.add(GRU(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "def rmae(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the Root Mean Absolute Error.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (Tensor): True values.\n",
        "    - y_pred (Tensor): Predicted values.\n",
        "\n",
        "    Returns:\n",
        "    - Tensor: Computed RMAE.\n",
        "    \"\"\"\n",
        "    return tf.sqrt(tf.reduce_mean(tf.abs(y_pred - y_true)))\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the Root Mean Squared Error.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (Tensor): True values.\n",
        "    - y_pred (Tensor): Predicted values.\n",
        "\n",
        "    Returns:\n",
        "    - Tensor: Computed RMSE.\n",
        "    \"\"\"\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
      ],
      "metadata": {
        "id": "krBo8qedE0gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[rmse, rmae])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5Ntv4G5gE0i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainmodel = model.fit(train_X, train_Y, epochs=50, batch_size=32, validation_data=(test_X, test_Y))"
      ],
      "metadata": {
        "id": "ZJ-qlILIEouQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save(\"google_model.h5\")\n"
      ],
      "metadata": {
        "id": "usj8iWIXEo0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Predicting Future Prices"
      ],
      "metadata": {
        "id": "InMJl26mF4Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_days(model, X_test_scaled, scaler, num_days):\n",
        "    \"\"\"\n",
        "    Predict the next 'num_days' days of stock prices using the trained model.\n",
        "\n",
        "    Parameters:\n",
        "    - model (tf.keras.Model): Trained model for prediction.\n",
        "    - X_test_scaled (numpy.ndarray): Scaled test data.\n",
        "    - scaler (MinMaxScaler): Scaler used to normalize data.\n",
        "    - num_days (int): Number of days to predict.\n",
        "\n",
        "    Returns:\n",
        "    - numpy.ndarray: Predicted stock prices for the next 'num_days' days.\n",
        "    \"\"\"\n",
        "    predicted = []\n",
        "    input_sequence = X_test_scaled[-1].reshape(1, 1, -1)\n",
        "    for _ in range(num_days):\n",
        "        next_day_pred = model.predict(input_sequence)\n",
        "        predicted.append(next_day_pred[0, 0])\n",
        "        input_sequence = np.append(input_sequence[:, :, 1:], next_day_pred.reshape(1, 1, 1), axis=2)\n",
        "    pred_price = scaler.inverse_transform(np.array(predicted).reshape(-1, 1))\n",
        "    return pred_price.flatten()\n"
      ],
      "metadata": {
        "id": "vSqlnnWAF5cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the next 3 days of Google stock prices\n",
        "num_days_to_predict = 3\n",
        "pred_price = predict_next_days(model, test_X, scaler, num_days_to_predict)"
      ],
      "metadata": {
        "id": "Iw1_hrU9F5gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the predicted prices\n",
        "for i in range(num_days_to_predict):\n",
        "    print(f\"Predicted close price for day {i + 1}: ${pred_price[i]:.2f}\")"
      ],
      "metadata": {
        "id": "G2aLkiHyF5nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Preparing Facebook Data and Training Model"
      ],
      "metadata": {
        "id": "g-4O1JLBGOgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and sort Facebook data from upsampled data\n",
        "facebook = upsampled_fb[upsampled_fb['symbol'] == 'FB']\n",
        "facebook = facebook.sort_values(by='date')\n",
        "facebook.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Normalize closing prices using MinMaxScaler\n",
        "close_prices = facebook['close'].values.reshape(-1, 1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "normalized_close_prices = scaler.fit_transform(close_prices)\n",
        "\n",
        "def make_dataset(data, win_size):\n",
        "    \"\"\"\n",
        "    Create datasets for training a time series model.\n",
        "\n",
        "    Parameters:\n",
        "    - data (numpy.ndarray): Normalized close prices.\n",
        "    - win_size (int): Size of the time window.\n",
        "\n",
        "    Returns:\n",
        "    - tuple: (X, Y) where X is the input features and Y is the target values.\n",
        "    \"\"\"\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data) - win_size):\n",
        "        X.append(data[i:i + win_size, 0])\n",
        "        Y.append(data[i + win_size, 0])\n",
        "    return np.array(X), np.array(Y)"
      ],
      "metadata": {
        "id": "z3I7dJ9YF5sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create training and testing datasets for Facebook\n",
        "win_size = 20\n",
        "X, Y = make_dataset(normalized_close_prices, win_size)\n",
        "X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "train_size = int(len(X) * 0.80)\n",
        "test_size = len(X) - train_size\n",
        "train_X, test_X = X[:train_size], X[train_size:]\n",
        "train_Y, test_Y = Y[:train_size], Y[train_size:]\n",
        "\n",
        "\n",
        "# Save test data\n",
        "with open('facebook_X_test.pkl', 'wb') as file:\n",
        "    pickle.dump(test_X, file)\n"
      ],
      "metadata": {
        "id": "qNdpf_QRF5y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and compile the GRU model for Facebook\n",
        "model = Sequential()\n",
        "model.add(GRU(units=50, return_sequences=True, input_shape=(1, win_size)))\n",
        "model.add(GRU(units=50, return_sequences=True))\n",
        "model.add(GRU(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Compute the Root Mean Squared Error.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (Tensor): True values.\n",
        "    - y_pred (Tensor): Predicted values.\n",
        "\n",
        "    Returns:\n",
        "    - Tensor: Computed RMSE.\n",
        "    \"\"\"\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
      ],
      "metadata": {
        "id": "huadf48NF51k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[rmse, rmae])\n",
        "\n",
        "# Train the model\n",
        "trainmodel = model.fit(train_X, train_Y, epochs=50, batch_size=32, validation_data=(test_X, test_Y))\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"fb_model.h5\")"
      ],
      "metadata": {
        "id": "KAc5_JCbF54E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Predicting Future Prices for Facebook"
      ],
      "metadata": {
        "id": "yeirxf__Guwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the next 3 days of Facebook stock prices\n",
        "pred_price = predict_next_days(model, test_X, scaler, num_days_to_predict)\n",
        "\n",
        "# Display the predicted prices\n",
        "for i in range(num_days_to_predict):\n",
        "    print(f\"Predicted close price for day {i + 1}: ${pred_price[i]:.2f}\")"
      ],
      "metadata": {
        "id": "2ngM1oQpF56d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Plotting Evaluation Metrics"
      ],
      "metadata": {
        "id": "0PMRXl9xG6It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation metrics for Google and Facebook\n",
        "Google = {\n",
        "    'RMSE': 0.1954,\n",
        "    'RMAE': 0.3946,\n",
        "    'LOSS': 0.0396\n",
        "}\n",
        "Facebook = {\n",
        "    'RMSE': 0.1909,\n",
        "    'RMAE': 0.3804,\n",
        "    'LOSS': 0.0401\n",
        "}\n",
        "\n",
        "# Plot evaluation metrics for Google and Facebook\n",
        "metrics = list(Google.keys())\n",
        "model1_values = list(Google.values())\n",
        "model2_values = list(Facebook.values())\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n"
      ],
      "metadata": {
        "id": "OZIH1G7AG0aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metrics for Google\n",
        "plt.subplot(1, 2, 1)\n",
        "bars = plt.bar(metrics, model1_values, color='b', alpha=0.7)\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Metric Values')\n",
        "plt.title('Evaluation Metrics for Google')\n",
        "for bar, value in zip(bars, model1_values):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.4f}', ha='center', va='bottom')\n",
        "\n"
      ],
      "metadata": {
        "id": "HALUO6uhG0ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot metrics for Facebook\n",
        "plt.subplot(1, 2, 2)\n",
        "bars = plt.bar(metrics, model2_values, color='r', alpha=0.7)\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Metric Values')\n",
        "plt.title('Evaluation Metrics for Facebook')\n",
        "for bar, value in zip(bars, model2_values):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.4f}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bReGuG7IG0h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_o7jGmZaG0k1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}